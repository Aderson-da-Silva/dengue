{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f909f755",
   "metadata": {},
   "source": [
    "## Alg de Predição usando LightGBM e Logist Regression\n",
    "\n",
    "Escolhas foram feitas devido a quantidade de dados e limitação de RAM e CPU:\n",
    "- 1 milhão de linhas de dados para treino;\n",
    "- 20% de toda a base para validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4924f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from optuna.visualization import plot_param_importances, plot_optimization_history\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ddce4d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pl.read_parquet(\"./data/dengue.parquet\")\n",
    "df_validation = pl.read_parquet('./data/dengue_val.parquet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c21ea2",
   "metadata": {},
   "source": [
    "### Limpando\n",
    "- Retirando parametros que ou o enferemeiro não terá acesso no momento ou que são 100% vazamento de dados\n",
    "- Pressuposto do modelo: o enfermeiro fara esses testes que foram mantidos ao atender o paciente na triagem ou serão já informados pelo paciente\n",
    "- Limitante: UF foi retirado porque há desbalanceamento entre estados mais ricos e mais pobres na questão de cadastramento e qualidade dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1be062cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_gravidade = [col for col in df_raw.columns if col.startswith('BIN_GRAV_')]\n",
    "cols_laboratorio = [\n",
    "    'BIN_ALRM_PLAQ',  # Exame de Sangue\n",
    "    'BIN_ALRM_HEMAT', # Exame de Sangue\n",
    "    'BIN_LEUCOPENIA', # Exame de Sangue\n",
    "    'BIN_ALRM_LIQ',   # USG/Exame físico complexo\n",
    "    'SG_UF'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be74885",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = df_raw.with_row_index(\"row_id\")\n",
    "df_raw = df_raw.drop(['DIAS_SINTOMA_INVESTIGACAO', 'DIAS_ALARME_INVESTIGACAO', 'DIAS_GRAVE_INVESTIGACAO'])\n",
    "df_raw = df_raw.drop(cols_gravidade)\n",
    "df_raw = df_raw.drop(cols_laboratorio)\n",
    "df_validation = df_validation.drop(['DIAS_SINTOMA_INVESTIGACAO', 'DIAS_ALARME_INVESTIGACAO', 'DIAS_GRAVE_INVESTIGACAO'])\n",
    "df_validation = df_validation.drop(cols_gravidade)\n",
    "df_validation = df_validation.drop(cols_laboratorio)\n",
    "train_mortes = df_raw.filter(pl.col(\"TARGET_OBITO\") == 1)\n",
    "n_mortos_train = train_mortes.height\n",
    "\n",
    "n_vivos_necessarios = 1_000_000 - n_mortos_train\n",
    "train_vivos = df_raw.filter(pl.col(\"TARGET_OBITO\") == 0).sample(n=n_vivos_necessarios, seed=42)\n",
    "\n",
    "# Juntar e embaralhar o treino\n",
    "df_train_pl = pl.concat([train_mortes, train_vivos]).sample(fraction=1.0, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2aa5b2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convertendo para Pandas...\n"
     ]
    }
   ],
   "source": [
    "print(\"Convertendo para Pandas...\")\n",
    "df_train = df_train_pl.drop(\"row_id\").to_pandas()\n",
    "df_val = df_validation.drop(\"row_id\").to_pandas()\n",
    "\n",
    "# Definição das Features\n",
    "features_categoricas = ['CS_SEXO', 'FAIXA_ETARIA']\n",
    "target = 'TARGET_OBITO'\n",
    "\n",
    "# Pegar todas as colunas menos o target\n",
    "features = [col for col in df_train.columns if col != target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2c0c174a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 30 columns):\n",
      " #   Column          Non-Null Count    Dtype   \n",
      "---  ------          --------------    -----   \n",
      " 0   TARGET_OBITO    1000000 non-null  int32   \n",
      " 1   IDADE_ANOS      999937 non-null   float64 \n",
      " 2   FAIXA_ETARIA    999968 non-null   object  \n",
      " 3   CS_SEXO         1000000 non-null  category\n",
      " 4   IS_GESTANTE     1000000 non-null  int32   \n",
      " 5   BIN_ALRM_HIPOT  1000000 non-null  int32   \n",
      " 6   BIN_ALRM_VOM    1000000 non-null  int32   \n",
      " 7   BIN_ALRM_SANG   1000000 non-null  int32   \n",
      " 8   BIN_ALRM_ABDOM  1000000 non-null  int32   \n",
      " 9   BIN_ALRM_LETAR  1000000 non-null  int32   \n",
      " 10  BIN_ALRM_HEPAT  1000000 non-null  int32   \n",
      " 11  BIN_DIABETES    1000000 non-null  int32   \n",
      " 12  BIN_HEMATOLOG   1000000 non-null  int32   \n",
      " 13  BIN_HEPATOPAT   1000000 non-null  int32   \n",
      " 14  BIN_RENAL       1000000 non-null  int32   \n",
      " 15  BIN_HIPERTENSA  1000000 non-null  int32   \n",
      " 16  BIN_ACIDO_PEPT  1000000 non-null  int32   \n",
      " 17  BIN_AUTO_IMUNE  1000000 non-null  int32   \n",
      " 18  BIN_FEBRE       1000000 non-null  int32   \n",
      " 19  BIN_MIALGIA     1000000 non-null  int32   \n",
      " 20  BIN_CEFALEIA    1000000 non-null  int32   \n",
      " 21  BIN_EXANTEMA    1000000 non-null  int32   \n",
      " 22  BIN_VOMITO      1000000 non-null  int32   \n",
      " 23  BIN_NAUSEA      1000000 non-null  int32   \n",
      " 24  BIN_DOR_COSTAS  1000000 non-null  int32   \n",
      " 25  BIN_CONJUNTVIT  1000000 non-null  int32   \n",
      " 26  BIN_ARTRITE     1000000 non-null  int32   \n",
      " 27  BIN_ARTRALGIA   1000000 non-null  int32   \n",
      " 28  BIN_PETEQUIA_N  1000000 non-null  int32   \n",
      " 29  BIN_DOR_RETRO   1000000 non-null  int32   \n",
      "dtypes: category(1), float64(1), int32(27), object(1)\n",
      "memory usage: 119.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fc7d7ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_validation\n",
    "del df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e4904eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in features_categoricas:\n",
    "    df_train[col] = df_train[col].astype('category')\n",
    "    df_val[col] = df_val[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5499b5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino (CV) shape: (1000000, 29)\n",
      "Holdout (Teste Final) shape: (1950576, 29)\n"
     ]
    }
   ],
   "source": [
    "X = df_train[features]\n",
    "y = df_train[target]\n",
    "\n",
    "X_holdout = df_val[features]\n",
    "y_holdout = df_val[target]\n",
    "\n",
    "print(f\"Treino (CV) shape: {X.shape}\")\n",
    "print(f\"Holdout (Teste Final) shape: {X_holdout.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c858205e",
   "metadata": {},
   "source": [
    "### Estudos do optuna para chegar nos melhores paramtros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d46aca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lgbm(trial):\n",
    "   \n",
    "    param_grid = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'n_jobs': -1,\n",
    "        'seed': 42,\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 256),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 15),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 20, 1000),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1.0, 10.0) \n",
    "    }\n",
    "\n",
    "   \n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    aucs = []\n",
    "    \n",
    "\n",
    "    for train_idx, val_idx in cv.split(X, y):\n",
    "        X_tr, y_tr = X.iloc[train_idx], y.iloc[train_idx]\n",
    "        X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "        dtrain = lgb.Dataset(X_tr, label=y_tr, categorical_feature=features_categoricas)\n",
    "        dval = lgb.Dataset(X_val, label=y_val, reference=dtrain, categorical_feature=features_categoricas)\n",
    "\n",
    "        model = lgb.train(\n",
    "            param_grid,\n",
    "            dtrain,\n",
    "            valid_sets=[dval],\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=30, verbose=False)]\n",
    "        )\n",
    "        \n",
    "        preds = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "        aucs.append(roc_auc_score(y_val, preds))\n",
    "    \n",
    "    mean_auc = np.mean(aucs)\n",
    "\n",
    "    print(f\"Trial {trial.number} finalizado. Média AUC: {mean_auc:.5f}\")\n",
    "    \n",
    "    return mean_auc\n",
    "\n",
    "\n",
    "def objective_lr(trial):\n",
    "    solver = trial.suggest_categorical('solver', ['lbfgs', 'liblinear'])\n",
    "    \n",
    "    if solver == 'liblinear':\n",
    "        penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
    "    else:\n",
    "        penalty = 'l2'\n",
    "\n",
    "    C = trial.suggest_float('C', 1e-4, 1e2, log=True)\n",
    "\n",
    "    numeric_features = [col for col in X.columns if col not in features_categoricas]\n",
    "    categorical_features = features_categoricas\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numeric_features),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore', drop='first'), categorical_features)\n",
    "        ])\n",
    "\n",
    "    # Classificador\n",
    "    clf = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', LogisticRegression(\n",
    "            C=C, \n",
    "            solver=solver, \n",
    "            penalty=penalty, \n",
    "            max_iter=1000, \n",
    "            random_state=42, \n",
    "            n_jobs=3 \n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42) \n",
    "    \n",
    "    scores = cross_val_score(clf, X, y, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "    s_m = scores.mean()\n",
    "    print(f\"Trial {trial.number} finalizado. Média AUC: {s_m:.5f}\")\n",
    "\n",
    "    return s_m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016e05b1",
   "metadata": {},
   "source": [
    "## Realizando os trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62e9e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Iniciando otimização do LightGBM...\n",
      "Trial 0 finalizado. Média AUC: 0.93312\n",
      "Trial 1 finalizado. Média AUC: 0.94403\n",
      "Trial 2 finalizado. Média AUC: 0.94088\n",
      "Trial 3 finalizado. Média AUC: 0.94152\n",
      "Trial 4 finalizado. Média AUC: 0.94439\n",
      "Trial 5 finalizado. Média AUC: 0.94209\n",
      "Trial 6 finalizado. Média AUC: 0.94406\n"
     ]
    }
   ],
   "source": [
    "print(\">>> Iniciando otimização do LightGBM...\")\n",
    "study_lgbm = optuna.create_study(direction='maximize', study_name=\"LGBM_Dengue\")\n",
    "study_lgbm.optimize(objective_lgbm, n_trials=50) # Aumente n_trials conforme seu tempo disponível\n",
    "\n",
    "print(f\"\\nMelhor AUC LightGBM: {study_lgbm.best_value:.5f}\")\n",
    "print(\"Melhores Params LGBM:\", study_lgbm.best_params)\n",
    "\n",
    "# 2. Estudo Logistic Regression\n",
    "print(\"\\n>>> Iniciando otimização da Regressão Logística...\")\n",
    "study_lr = optuna.create_study(direction='maximize', study_name=\"LogReg_Dengue\")\n",
    "study_lr.optimize(objective_lr, n_trials=25) \n",
    "\n",
    "print(f\"\\nMelhor AUC LogReg: {study_lr.best_value:.5f}\")\n",
    "print(\"Melhores Params LogReg:\", study_lr.best_params)\n",
    "\n",
    "# Comparação Final\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(f\"Vencedor: {'LightGBM' if study_lgbm.best_value > study_lr.best_value else 'Logistic Regression'}\")\n",
    "print(f\"Diferença de AUC: {abs(study_lgbm.best_value - study_lr.best_value):.5f}\")\n",
    "print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521c4eed",
   "metadata": {},
   "source": [
    "## Importancia das variáves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fb49b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_param_importances(study_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16048845",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_lgbm = study_lgbm.best_params\n",
    "best_params_lr = study_lr.best_params\n",
    "\n",
    "print(\"Melhores parâmetros LightGBM:\", best_params_lgbm)\n",
    "print(\"Melhores parâmetros LogReg:\", best_params_lr)\n",
    "\n",
    "target_recall = 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7f4dd3",
   "metadata": {},
   "source": [
    "## Função de avaliação do modelo final com plotagem de gráfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f212b87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [Treino] T_LOW definido em:  0.00504 (Recall esperado ~99%)\n",
      "   [Treino] T_HIGH definido em: 0.29346 (F1 Max esperado)\n"
     ]
    }
   ],
   "source": [
    "def avaliar_modelo(nome_modelo, y_train, y_oof_probs, y_holdout, y_proba_holdout, df_holdout_base):\n",
    "    print(f\"\\n{'='*20} AVALIAÇÃO: {nome_modelo} {'='*20}\")\n",
    "    \n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_train, y_oof_probs)\n",
    "    \n",
    "    try:\n",
    "        idx_low = np.where(recalls >= target_recall)[0][-1] \n",
    "        t_low = thresholds[idx_low]\n",
    "    except IndexError:\n",
    "        t_low = 0.01 \n",
    "    \n",
    "    # T_HIGH (Max F1)\n",
    "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-10)\n",
    "    idx_high = np.argmax(f1_scores)\n",
    "    t_high = thresholds[idx_high]\n",
    "    \n",
    "    if t_high <= t_low:\n",
    "        t_high = t_low + 0.05\n",
    "        \n",
    "    print(f\"   [Treino] T_LOW definido em:  {t_low:.5f} (Recall esperado ~{target_recall*100:.0f}%)\")\n",
    "    print(f\"   [Treino] T_HIGH definido em: {t_high:.5f} (F1 Max esperado)\")\n",
    "\n",
    "    # 2. Aplicar Thresholds no Holdout\n",
    "    conditions = [\n",
    "        (y_proba_holdout < t_low),\n",
    "        (y_proba_holdout >= t_low) & (y_proba_holdout < t_high),\n",
    "        (y_proba_holdout >= t_high)\n",
    "    ]\n",
    "    choices = ['1. Verde', '2. Amarelo', '3. Vermelho']\n",
    "    \n",
    "    df_result = df_holdout_base.copy()\n",
    "    df_result['Risco'] = np.select(conditions, choices, default='Erro')\n",
    "\n",
    "    resumo = pd.crosstab(df_result['Risco'], df_result[target].map({0: 'Vivos', 1: 'Óbitos'}))\n",
    "    resumo = resumo.reindex(['1. Verde', '2. Amarelo', '3. Vermelho']).fillna(0)\n",
    "    resumo['Total'] = resumo.sum(axis=1)\n",
    "    resumo['%_dos_Obitos_Reais'] = (resumo['Óbitos'] / resumo['Óbitos'].sum()) * 100\n",
    "    \n",
    "    print(f\"\\n>>> PERFORMANCE REAL ({nome_modelo}) <<<\")\n",
    "    print(resumo)\n",
    "    \n",
    "    obitos_total = resumo['Óbitos'].sum()\n",
    "    obitos_pegos = resumo.loc[['2. Amarelo', '3. Vermelho'], 'Óbitos'].sum()\n",
    "    recall_real = obitos_pegos / obitos_total if obitos_total > 0 else 0\n",
    "\n",
    "    print(f\"\\nRecall Real Atingido: {recall_real:.2%}\")\n",
    "    if recall_real < target_recall:\n",
    "        print(f\"Nota: O Recall caiu ({target_recall*100}% -> {recall_real*100:.2f}%). Considere baixar T_LOW.\")\n",
    "    else:\n",
    "        print(\"Sucesso: A generalização das zonas de risco funcionou.\")\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.kdeplot(y_proba_holdout[y_holdout == 0], fill=True, color='blue', alpha=0.3, label='Holdout: Sobreviventes')\n",
    "    sns.kdeplot(y_proba_holdout[y_holdout == 1], fill=True, color='red', alpha=0.3, label='Holdout: Óbitos')\n",
    "    plt.axvline(t_low, color='green', linestyle='--', label=f'T_Low: {t_low:.3f}')\n",
    "    plt.axvline(t_high, color='red', linestyle='--', label=f'T_High: {t_high:.3f}')\n",
    "    plt.title(f'Distribuição de Probabilidades - {nome_modelo}')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8544031d",
   "metadata": {},
   "source": [
    "## Melhor modelo LightGBM com hiperâmetros otimizados sendo rodados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f50cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> 4. Treinando Modelo Final e Testando no Holdout...\n"
     ]
    }
   ],
   "source": [
    "print(\">>> Processando LightGBM Final...\")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "y_oof_lgbm = np.zeros(len(X))\n",
    "\n",
    "fixed_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'verbosity': -1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'seed': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "final_params_lgbm = {**fixed_params, **best_params_lgbm}\n",
    "\n",
    "for train_idx, val_idx in cv.split(X, y):\n",
    "    X_tr, y_tr = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "    \n",
    "    dtrain = lgb.Dataset(X_tr, label=y_tr, categorical_feature=features_categoricas)\n",
    "    dval = lgb.Dataset(X_val, label=y_val, reference=dtrain, categorical_feature=features_categoricas)\n",
    "    \n",
    "    model_cv = lgb.train(final_params_lgbm, dtrain, num_boost_round=1000, \n",
    "                         valid_sets=[dval], callbacks=[lgb.early_stopping(30, verbose=False)])\n",
    "    \n",
    "    y_oof_lgbm[val_idx] = model_cv.predict(X_val, num_iteration=model_cv.best_iteration)\n",
    "\n",
    "print(\"Treinando LightGBM em todo o dataset...\")\n",
    "dtrain_full = lgb.Dataset(X, label=y, categorical_feature=features_categoricas)\n",
    "final_model_lgbm = lgb.train(final_params_lgbm, dtrain_full, num_boost_round=1000)\n",
    "\n",
    "y_proba_holdout_lgbm = final_model_lgbm.predict(X_holdout)\n",
    "\n",
    "avaliar_modelo(\"LightGBM Otimizado\", y, y_oof_lgbm, y_holdout, y_proba_holdout_lgbm, df_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71951be",
   "metadata": {},
   "source": [
    "## Melhor modelo Logistic Regression sendo rodado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1b70c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\">>> Processando Logistic Regression Final...\")\n",
    "\n",
    "numeric_features = [col for col in X.columns if col not in features_categoricas]\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', drop='first'), features_categoricas)\n",
    "    ])\n",
    "\n",
    "solver = best_params_lr['solver']\n",
    "C = best_params_lr['C']\n",
    "penalty = best_params_lr.get('penalty', 'l2') \n",
    "\n",
    "final_pipe_lr = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(\n",
    "        C=C, \n",
    "        solver=solver, \n",
    "        penalty=penalty, \n",
    "        max_iter=1000, \n",
    "        random_state=42, \n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "print(\"Gerando OOF predictions para LR (pode demorar um pouco)...\")\n",
    "y_oof_lr = cross_val_predict(final_pipe_lr, X, y, cv=3, method='predict_proba', n_jobs=-1)[:, 1]\n",
    "\n",
    "print(\"Treinando Logistic Regression em todo o dataset...\")\n",
    "final_pipe_lr.fit(X, y)\n",
    "\n",
    "y_proba_holdout_lr = final_pipe_lr.predict_proba(X_holdout)[:, 1]\n",
    "\n",
    "avaliar_modelo(\"Logistic Regression Otimizada\", y, y_oof_lr, y_holdout, y_proba_holdout_lr, df_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dengue",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
